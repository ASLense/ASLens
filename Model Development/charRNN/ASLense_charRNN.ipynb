{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pfz70c6560_t",
    "outputId": "2dc76d53-6398-4b6c-ad48-e10d79375857"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "import pandas as pd\n",
    "\n",
    "REPO_ID = \"Kunj07/openwebtext\"\n",
    "FILENAME = \"output_val.txt\"\n",
    "\n",
    "dataset = hf_hub_download(repo_id=REPO_ID, filename=FILENAME, repo_type=\"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "9-kShxvt6RAc",
    "outputId": "3fa73252-4231-49b9-af45-876eba6bf21e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/root/.cache/huggingface/hub/datasets--Kunj07--openwebtext/snapshots/e99d9057358f6dfab09ff98ba0b68f55d5b1f106/output_val.txt'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "PACob-TTIgzk"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import string\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YNUg_2sx7jc5",
    "outputId": "a758ccab-961f-4bf0-fd4f-3661bd56f234"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " '!',\n",
       " '?',\n",
       " '.',\n",
       " ',',\n",
       " '\"',\n",
       " '(',\n",
       " ')',\n",
       " '&',\n",
       " '+',\n",
       " '-',\n",
       " '/',\n",
       " '@',\n",
       " '%',\n",
       " '–',\n",
       " ':',\n",
       " ' ',\n",
       " '\\n']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "accepted_text= string.ascii_lowercase+ string.digits + '!?.,\\\"()&+-/@%–' + \":\" + \" \" + \"\\n\"\n",
    "chars = [x for x in accepted_text]\n",
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3f0Xxc9R_KqI",
    "outputId": "3aa835d5-cc17-4a8e-e2b3-9820a3ef6085"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<SOS>': 0,\n",
       " '<UNK>': 1,\n",
       " 'a': 2,\n",
       " 'b': 3,\n",
       " 'c': 4,\n",
       " 'd': 5,\n",
       " 'e': 6,\n",
       " 'f': 7,\n",
       " 'g': 8,\n",
       " 'h': 9,\n",
       " 'i': 10,\n",
       " 'j': 11,\n",
       " 'k': 12,\n",
       " 'l': 13,\n",
       " 'm': 14,\n",
       " 'n': 15,\n",
       " 'o': 16,\n",
       " 'p': 17,\n",
       " 'q': 18,\n",
       " 'r': 19,\n",
       " 's': 20,\n",
       " 't': 21,\n",
       " 'u': 22,\n",
       " 'v': 23,\n",
       " 'w': 24,\n",
       " 'x': 25,\n",
       " 'y': 26,\n",
       " 'z': 27,\n",
       " '0': 28,\n",
       " '1': 29,\n",
       " '2': 30,\n",
       " '3': 31,\n",
       " '4': 32,\n",
       " '5': 33,\n",
       " '6': 34,\n",
       " '7': 35,\n",
       " '8': 36,\n",
       " '9': 37,\n",
       " '!': 38,\n",
       " '?': 39,\n",
       " '.': 40,\n",
       " ',': 41,\n",
       " '\"': 42,\n",
       " '(': 43,\n",
       " ')': 44,\n",
       " '&': 45,\n",
       " '+': 46,\n",
       " '-': 47,\n",
       " '/': 48,\n",
       " '@': 49,\n",
       " '%': 50,\n",
       " '–': 51,\n",
       " ':': 52,\n",
       " ' ': 53,\n",
       " '\\n': 54,\n",
       " '<EOS>': 55}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary ={}\n",
    "vocabulary[\"<SOS>\"]=0\n",
    "vocabulary[\"<UNK>\"]=1\n",
    "\n",
    "for i,char in enumerate(chars):\n",
    "  vocabulary[char]=i+2\n",
    "vocabulary[\"<EOS>\"]=i+3\n",
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "MYVdZnoy-6BH"
   },
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "  def __init__(self,vocab,chars):\n",
    "    self.vocab = vocab\n",
    "    self.chars = chars\n",
    "\n",
    "  def __call__(self,text):\n",
    "    encoded = []\n",
    "    for char in text.lower():\n",
    "      if char not in self.chars:\n",
    "        encoded.append(self.vocab[\"<UNK>\"])\n",
    "        continue\n",
    "      encoded.append(self.vocab[char])\n",
    "    encoded = torch.tensor(encoded).view(1,-1)\n",
    "\n",
    "\n",
    "    return encoded\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "deK4wWhkFjB1"
   },
   "outputs": [],
   "source": [
    "texts=[]\n",
    "with open(dataset, \"r\") as f:\n",
    "    for i in range(6_000_001):\n",
    "      f.readline()\n",
    "      if i>5_000_000:\n",
    "        texts.append(f.readline())\n",
    "texts=texts[1:]\n",
    "texts=[s.replace('\\x00', '') for s in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "cuexj2buMAqx"
   },
   "outputs": [],
   "source": [
    "texts =\"\".join(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 140
    },
    "id": "4oQ6fCWPMkyr",
    "outputId": "26ba1db3-614a-435c-8ff4-2b3041d28abe"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'This article is published as part of the IDG Contributor Network. Want to Join?0876431-09fb0d1d3395844927c22de2ad1dd9c2.txt0000644000000000000000000001767500000000000015135 0ustar  00000000000000Breaking News Emails Get breaking news alerts and special reports. The news and stories that matter, delivered weekday mornings.\\nMarch 6, 2016, 10:08 AM GMT / Updated March 6, 2016, 12:57 PM GMT By Erik Ortiz\\nAiling octogenarian Anita Morrison was suffering from sharp stomach pains last December when she came across a clinic online called the New Birth New Life \\u200bMedical Center & Urgent Care.\\nShe called the office, located in her hometown of West Palm Beach, Florida, and spoke with a man named Dr. Malachi Love-Robinson, who offered to pay her an in-home visit.\\nWearing a white lab coat and stethoscope slung around his neck, Love-Robinson examined Morrison, focusing on her legs, heart and lungs, she said. He told her she had arthritis. Then he sold her natural vitamins to dull the discomfort.\\nBut that wasn\\'t the last time Morrison, 86, would hear from \"Dr. Love.\"\\nRelated: Florida Teen Arrested for Performing Exam as Fake Doctor\\nShe said she allowed the baby-faced physician to return four more times — although by early January, she realized something wasn\\'t right inside her home. Personal checks went missing. In a probable cause affidavit, she told the Palm Beach County Sheriff\\'s Office that she believed Love-Robinson had gained access to her checking account and had stolen her identity to the tune of over $34,500.\\nLove-Robinson was arrested late Tuesday in connection with Morrison\\'s case — just two weeks after an earlier arrest in which authorities say he faked his identity by masquerading as a medical doctor and gave an undercover officer an exam.\\n\"Just because you saw a season of \\'Grey\\'s Anatomy\\' doesn\\'t mean you could practice medicine,\" the Palm Beach County Sheriff\\'s Office sneered in a Feb. 16 tweet.\\nMalachi Love-Robinson, 18, was booked on the charge of practicing medicine without a license and faces other charges, Florida police said. Palm Beach County Sheriff\\'s Office\\nHow Love-Robinson — just 18 years old with no official medical training — allegedly deceived people in a \"Catch Me If You Can\"-like con remains under investigation. But authorities and experts say it was a duplicitous plan built on lies and \"loopholes\" in the health care system.\\nLove-Robinson said in a rambling news conference last month that he never implied that he was a doctor of medicine, and that he has been interested in naturopathic treatment, which involves herbal remedies and other alternatives.\\n\"This was not about me trying to hurt people, this was not about me trying to say I\\'m a medical doctor,\" Love-Robinson said. \"Because, honestly, people have misconstrued my name, they misconstrued my age, they\\'ve misconstrued where I\\'m from, they\\'ve misconstrued everything about me.\"\\nBut officials say it was the young \"doctor\" who twisted his identity — by managing to open his own prac'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0000:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "qnGtWAT7FC2u"
   },
   "outputs": [],
   "source": [
    "#import h5py\n",
    "#with h5py.File('text_data.h5', 'w') as h5_file:\n",
    "##    dt = h5py.string_dtype(encoding='utf-8')\n",
    " #   dset = h5_file.create_dataset('text', texts, dtype=dt)\n",
    "\n",
    "    # Write line by line\n",
    "    ##for i, line in enumerate(texts):\n",
    "      #  dset[i] = line.strip()  # Remove '\\n' if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oep2t5gvCMoh",
    "outputId": "e3318b49-b472-48e7-cad5-0eee65048fbf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5,  2, 23, 22,  5, 53, 11,  6, 53,  9,  2,  7,  1, 10, 27]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test of the tokenizer\n",
    "tokenizer = Tokenizer(vocabulary,chars)\n",
    "tokenizer(\"Davud je haf[iz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true,
    "id": "03oe47yH76L_"
   },
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "  def __init__(self, dataset_path, texts, tokenizer=None, seq_len=30):\n",
    "    self.dataset_path=dataset_path\n",
    "    self.tokenizer=tokenizer\n",
    "    self.text=texts\n",
    "    self.seq_len=seq_len\n",
    "  def __len__(self):\n",
    "    return len(self.text)-self.seq_len\n",
    "  def __getitem__ (self, idx):\n",
    "    x=self.text[idx:idx+self.seq_len]\n",
    "    y=self.text[idx+self.seq_len]\n",
    "    if self.tokenizer is not None:\n",
    "      x=self.tokenizer(x)\n",
    "      y=self.tokenizer(y)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "0yC2Ask9VkgF",
    "outputId": "e8332bcf-50b2-4df8-d5d8-713a08e164dd"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'This article is published as part of the IDG Contributor Network. Want to Join?0876431-09fb0d1d33958'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gZmYWhsmT5Vh",
    "outputId": "c2720bb4-f8a1-4ef7-da27-85d0dfd75366"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x=tensor([[21,  9, 10, 20, 53,  2, 19, 21, 10,  4, 13,  6, 53, 10, 20, 53, 17, 22,\n",
      "          3, 13, 10, 20,  9,  6,  5, 53,  2, 20, 53, 17]]), y=tensor([[2]])\n",
      "torch.Size([1, 30]) torch.Size([1, 1])\n",
      "x=tensor([[ 9, 10, 20, 53,  2, 19, 21, 10,  4, 13,  6, 53, 10, 20, 53, 17, 22,  3,\n",
      "         13, 10, 20,  9,  6,  5, 53,  2, 20, 53, 17,  2]]), y=tensor([[19]])\n",
      "torch.Size([1, 30]) torch.Size([1, 1])\n",
      "x=tensor([[10, 20, 53,  2, 19, 21, 10,  4, 13,  6, 53, 10, 20, 53, 17, 22,  3, 13,\n",
      "         10, 20,  9,  6,  5, 53,  2, 20, 53, 17,  2, 19]]), y=tensor([[21]])\n",
      "torch.Size([1, 30]) torch.Size([1, 1])\n",
      "x=tensor([[20, 53,  2, 19, 21, 10,  4, 13,  6, 53, 10, 20, 53, 17, 22,  3, 13, 10,\n",
      "         20,  9,  6,  5, 53,  2, 20, 53, 17,  2, 19, 21]]), y=tensor([[53]])\n",
      "torch.Size([1, 30]) torch.Size([1, 1])\n",
      "x=tensor([[53,  2, 19, 21, 10,  4, 13,  6, 53, 10, 20, 53, 17, 22,  3, 13, 10, 20,\n",
      "          9,  6,  5, 53,  2, 20, 53, 17,  2, 19, 21, 53]]), y=tensor([[16]])\n",
      "torch.Size([1, 30]) torch.Size([1, 1])\n",
      "x=tensor([[ 2, 19, 21, 10,  4, 13,  6, 53, 10, 20, 53, 17, 22,  3, 13, 10, 20,  9,\n",
      "          6,  5, 53,  2, 20, 53, 17,  2, 19, 21, 53, 16]]), y=tensor([[7]])\n",
      "torch.Size([1, 30]) torch.Size([1, 1])\n",
      "x=tensor([[19, 21, 10,  4, 13,  6, 53, 10, 20, 53, 17, 22,  3, 13, 10, 20,  9,  6,\n",
      "          5, 53,  2, 20, 53, 17,  2, 19, 21, 53, 16,  7]]), y=tensor([[53]])\n",
      "torch.Size([1, 30]) torch.Size([1, 1])\n",
      "x=tensor([[21, 10,  4, 13,  6, 53, 10, 20, 53, 17, 22,  3, 13, 10, 20,  9,  6,  5,\n",
      "         53,  2, 20, 53, 17,  2, 19, 21, 53, 16,  7, 53]]), y=tensor([[21]])\n",
      "torch.Size([1, 30]) torch.Size([1, 1])\n",
      "x=tensor([[10,  4, 13,  6, 53, 10, 20, 53, 17, 22,  3, 13, 10, 20,  9,  6,  5, 53,\n",
      "          2, 20, 53, 17,  2, 19, 21, 53, 16,  7, 53, 21]]), y=tensor([[9]])\n",
      "torch.Size([1, 30]) torch.Size([1, 1])\n",
      "x=tensor([[ 4, 13,  6, 53, 10, 20, 53, 17, 22,  3, 13, 10, 20,  9,  6,  5, 53,  2,\n",
      "         20, 53, 17,  2, 19, 21, 53, 16,  7, 53, 21,  9]]), y=tensor([[6]])\n",
      "torch.Size([1, 30]) torch.Size([1, 1])\n"
     ]
    }
   ],
   "source": [
    "df=TextDataset('',texts[0:100_000], tokenizer=tokenizer)\n",
    "s=0\n",
    "for i,k in df:\n",
    "  print(f\"x={i}, y={k}\")\n",
    "  print(i.shape,k.shape)\n",
    "  s+=1\n",
    "  if s==10:\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5Ie9bg99WbC3",
    "outputId": "1608e013-35fb-4263-e804-262705e81b42"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99970"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "Oo22IaEJYw9q"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(df, batch_size=32, shuffle=False,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dc_Yr131ZBtr",
    "outputId": "556a4263-d6b3-4dca-c7d4-122f78c13f03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[21,  9, 10, 20, 53,  2, 19, 21, 10,  4, 13,  6, 53, 10, 20, 53, 17,\n",
      "          22,  3, 13, 10, 20,  9,  6,  5, 53,  2, 20, 53, 17]],\n",
      "\n",
      "        [[ 9, 10, 20, 53,  2, 19, 21, 10,  4, 13,  6, 53, 10, 20, 53, 17, 22,\n",
      "           3, 13, 10, 20,  9,  6,  5, 53,  2, 20, 53, 17,  2]],\n",
      "\n",
      "        [[10, 20, 53,  2, 19, 21, 10,  4, 13,  6, 53, 10, 20, 53, 17, 22,  3,\n",
      "          13, 10, 20,  9,  6,  5, 53,  2, 20, 53, 17,  2, 19]],\n",
      "\n",
      "        [[20, 53,  2, 19, 21, 10,  4, 13,  6, 53, 10, 20, 53, 17, 22,  3, 13,\n",
      "          10, 20,  9,  6,  5, 53,  2, 20, 53, 17,  2, 19, 21]],\n",
      "\n",
      "        [[53,  2, 19, 21, 10,  4, 13,  6, 53, 10, 20, 53, 17, 22,  3, 13, 10,\n",
      "          20,  9,  6,  5, 53,  2, 20, 53, 17,  2, 19, 21, 53]],\n",
      "\n",
      "        [[ 2, 19, 21, 10,  4, 13,  6, 53, 10, 20, 53, 17, 22,  3, 13, 10, 20,\n",
      "           9,  6,  5, 53,  2, 20, 53, 17,  2, 19, 21, 53, 16]],\n",
      "\n",
      "        [[19, 21, 10,  4, 13,  6, 53, 10, 20, 53, 17, 22,  3, 13, 10, 20,  9,\n",
      "           6,  5, 53,  2, 20, 53, 17,  2, 19, 21, 53, 16,  7]],\n",
      "\n",
      "        [[21, 10,  4, 13,  6, 53, 10, 20, 53, 17, 22,  3, 13, 10, 20,  9,  6,\n",
      "           5, 53,  2, 20, 53, 17,  2, 19, 21, 53, 16,  7, 53]],\n",
      "\n",
      "        [[10,  4, 13,  6, 53, 10, 20, 53, 17, 22,  3, 13, 10, 20,  9,  6,  5,\n",
      "          53,  2, 20, 53, 17,  2, 19, 21, 53, 16,  7, 53, 21]],\n",
      "\n",
      "        [[ 4, 13,  6, 53, 10, 20, 53, 17, 22,  3, 13, 10, 20,  9,  6,  5, 53,\n",
      "           2, 20, 53, 17,  2, 19, 21, 53, 16,  7, 53, 21,  9]],\n",
      "\n",
      "        [[13,  6, 53, 10, 20, 53, 17, 22,  3, 13, 10, 20,  9,  6,  5, 53,  2,\n",
      "          20, 53, 17,  2, 19, 21, 53, 16,  7, 53, 21,  9,  6]],\n",
      "\n",
      "        [[ 6, 53, 10, 20, 53, 17, 22,  3, 13, 10, 20,  9,  6,  5, 53,  2, 20,\n",
      "          53, 17,  2, 19, 21, 53, 16,  7, 53, 21,  9,  6, 53]],\n",
      "\n",
      "        [[53, 10, 20, 53, 17, 22,  3, 13, 10, 20,  9,  6,  5, 53,  2, 20, 53,\n",
      "          17,  2, 19, 21, 53, 16,  7, 53, 21,  9,  6, 53, 10]],\n",
      "\n",
      "        [[10, 20, 53, 17, 22,  3, 13, 10, 20,  9,  6,  5, 53,  2, 20, 53, 17,\n",
      "           2, 19, 21, 53, 16,  7, 53, 21,  9,  6, 53, 10,  5]],\n",
      "\n",
      "        [[20, 53, 17, 22,  3, 13, 10, 20,  9,  6,  5, 53,  2, 20, 53, 17,  2,\n",
      "          19, 21, 53, 16,  7, 53, 21,  9,  6, 53, 10,  5,  8]],\n",
      "\n",
      "        [[53, 17, 22,  3, 13, 10, 20,  9,  6,  5, 53,  2, 20, 53, 17,  2, 19,\n",
      "          21, 53, 16,  7, 53, 21,  9,  6, 53, 10,  5,  8, 53]],\n",
      "\n",
      "        [[17, 22,  3, 13, 10, 20,  9,  6,  5, 53,  2, 20, 53, 17,  2, 19, 21,\n",
      "          53, 16,  7, 53, 21,  9,  6, 53, 10,  5,  8, 53,  4]],\n",
      "\n",
      "        [[22,  3, 13, 10, 20,  9,  6,  5, 53,  2, 20, 53, 17,  2, 19, 21, 53,\n",
      "          16,  7, 53, 21,  9,  6, 53, 10,  5,  8, 53,  4, 16]],\n",
      "\n",
      "        [[ 3, 13, 10, 20,  9,  6,  5, 53,  2, 20, 53, 17,  2, 19, 21, 53, 16,\n",
      "           7, 53, 21,  9,  6, 53, 10,  5,  8, 53,  4, 16, 15]],\n",
      "\n",
      "        [[13, 10, 20,  9,  6,  5, 53,  2, 20, 53, 17,  2, 19, 21, 53, 16,  7,\n",
      "          53, 21,  9,  6, 53, 10,  5,  8, 53,  4, 16, 15, 21]],\n",
      "\n",
      "        [[10, 20,  9,  6,  5, 53,  2, 20, 53, 17,  2, 19, 21, 53, 16,  7, 53,\n",
      "          21,  9,  6, 53, 10,  5,  8, 53,  4, 16, 15, 21, 19]],\n",
      "\n",
      "        [[20,  9,  6,  5, 53,  2, 20, 53, 17,  2, 19, 21, 53, 16,  7, 53, 21,\n",
      "           9,  6, 53, 10,  5,  8, 53,  4, 16, 15, 21, 19, 10]],\n",
      "\n",
      "        [[ 9,  6,  5, 53,  2, 20, 53, 17,  2, 19, 21, 53, 16,  7, 53, 21,  9,\n",
      "           6, 53, 10,  5,  8, 53,  4, 16, 15, 21, 19, 10,  3]],\n",
      "\n",
      "        [[ 6,  5, 53,  2, 20, 53, 17,  2, 19, 21, 53, 16,  7, 53, 21,  9,  6,\n",
      "          53, 10,  5,  8, 53,  4, 16, 15, 21, 19, 10,  3, 22]],\n",
      "\n",
      "        [[ 5, 53,  2, 20, 53, 17,  2, 19, 21, 53, 16,  7, 53, 21,  9,  6, 53,\n",
      "          10,  5,  8, 53,  4, 16, 15, 21, 19, 10,  3, 22, 21]],\n",
      "\n",
      "        [[53,  2, 20, 53, 17,  2, 19, 21, 53, 16,  7, 53, 21,  9,  6, 53, 10,\n",
      "           5,  8, 53,  4, 16, 15, 21, 19, 10,  3, 22, 21, 16]],\n",
      "\n",
      "        [[ 2, 20, 53, 17,  2, 19, 21, 53, 16,  7, 53, 21,  9,  6, 53, 10,  5,\n",
      "           8, 53,  4, 16, 15, 21, 19, 10,  3, 22, 21, 16, 19]],\n",
      "\n",
      "        [[20, 53, 17,  2, 19, 21, 53, 16,  7, 53, 21,  9,  6, 53, 10,  5,  8,\n",
      "          53,  4, 16, 15, 21, 19, 10,  3, 22, 21, 16, 19, 53]],\n",
      "\n",
      "        [[53, 17,  2, 19, 21, 53, 16,  7, 53, 21,  9,  6, 53, 10,  5,  8, 53,\n",
      "           4, 16, 15, 21, 19, 10,  3, 22, 21, 16, 19, 53, 15]],\n",
      "\n",
      "        [[17,  2, 19, 21, 53, 16,  7, 53, 21,  9,  6, 53, 10,  5,  8, 53,  4,\n",
      "          16, 15, 21, 19, 10,  3, 22, 21, 16, 19, 53, 15,  6]],\n",
      "\n",
      "        [[ 2, 19, 21, 53, 16,  7, 53, 21,  9,  6, 53, 10,  5,  8, 53,  4, 16,\n",
      "          15, 21, 19, 10,  3, 22, 21, 16, 19, 53, 15,  6, 21]],\n",
      "\n",
      "        [[19, 21, 53, 16,  7, 53, 21,  9,  6, 53, 10,  5,  8, 53,  4, 16, 15,\n",
      "          21, 19, 10,  3, 22, 21, 16, 19, 53, 15,  6, 21, 24]]])\n",
      "\n",
      "\n",
      "tensor([[[ 2]],\n",
      "\n",
      "        [[19]],\n",
      "\n",
      "        [[21]],\n",
      "\n",
      "        [[53]],\n",
      "\n",
      "        [[16]],\n",
      "\n",
      "        [[ 7]],\n",
      "\n",
      "        [[53]],\n",
      "\n",
      "        [[21]],\n",
      "\n",
      "        [[ 9]],\n",
      "\n",
      "        [[ 6]],\n",
      "\n",
      "        [[53]],\n",
      "\n",
      "        [[10]],\n",
      "\n",
      "        [[ 5]],\n",
      "\n",
      "        [[ 8]],\n",
      "\n",
      "        [[53]],\n",
      "\n",
      "        [[ 4]],\n",
      "\n",
      "        [[16]],\n",
      "\n",
      "        [[15]],\n",
      "\n",
      "        [[21]],\n",
      "\n",
      "        [[19]],\n",
      "\n",
      "        [[10]],\n",
      "\n",
      "        [[ 3]],\n",
      "\n",
      "        [[22]],\n",
      "\n",
      "        [[21]],\n",
      "\n",
      "        [[16]],\n",
      "\n",
      "        [[19]],\n",
      "\n",
      "        [[53]],\n",
      "\n",
      "        [[15]],\n",
      "\n",
      "        [[ 6]],\n",
      "\n",
      "        [[21]],\n",
      "\n",
      "        [[24]],\n",
      "\n",
      "        [[16]]])\n"
     ]
    }
   ],
   "source": [
    "for i, k in train_loader:\n",
    "  print(i)\n",
    "  print(\"\\n\")\n",
    "  print(k)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P4fbAIDjQto8"
   },
   "outputs": [],
   "source": [
    "with h5py.File('test_data.h5') as f:\n",
    "  print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wGEBgKjED2cr",
    "outputId": "4d7bfe40-2e5a-49fa-b04d-e2cc4799f699"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33175084\n"
     ]
    }
   ],
   "source": [
    "f = open(dataset,\"r\")\n",
    "print(len(f.readlines()))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "YOAEUe1e79tB"
   },
   "outputs": [],
   "source": [
    "s =open(dataset)\n",
    "s.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "98wFl6TL8NQ7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
