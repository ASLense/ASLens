{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6950eade-5f41-445b-8d25-dd05535f4daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import mediapipe as mp\n",
    "from constants import LIPS_POSITIONS\n",
    "from google.protobuf.json_format import MessageToDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7373f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Drawing:\n",
    "    def __init__(self):\n",
    "        self.mpFace = mp.solutions.face_mesh\n",
    "        self.mpDrawHands = mp.solutions.drawing_utils # Initializing drawing object for hands\n",
    "        self.mpDrawFace = mp.solutions.drawing_utils # Initializing drawing object for Face\n",
    "        self.mp_drawing_styles =mp.solutions.drawing_styles\n",
    "        self.mp_drawing_face = self.mpDrawFace.DrawingSpec(color=(0,0,200),thickness=0,circle_radius=1) #Initializing drawing specifications for face\n",
    "        self.mp_drawing_hands = self.mpDrawHands.DrawingSpec(color=(255,0,0),thickness=0,circle_radius=1) #Initializing drawing specifications for hand\n",
    "        self.mpHands = mp.solutions.hands\n",
    "    def drawLandmarks(self,img,resultsFace,resultsHands):\n",
    "        img=img.copy()\n",
    "        if resultsFace.multi_face_landmarks:\n",
    "            for face_landmarks in resultsFace.multi_face_landmarks:   \n",
    "                self.mpDrawFace.draw_landmarks( # Draw face lendmark\n",
    "                  image=img,\n",
    "                  landmark_list=face_landmarks,\n",
    "                  connections=self.mpFace.FACEMESH_CONTOURS,\n",
    "                  landmark_drawing_spec=self.mp_drawing_face,\n",
    "                  connection_drawing_spec=self.mp_drawing_styles.get_default_face_mesh_tesselation_style())\n",
    "            \n",
    "        if \"Left\" in resultsHands.keys():\n",
    "            self.mpDrawHands.draw_landmarks(image=img, # Draw hand landmarks\n",
    "                                landmark_list=resultsHands[\"Left\"],\n",
    "                                      \n",
    "                                connections=self.mpHands.HAND_CONNECTIONS,\n",
    "                                landmark_drawing_spec=self.mp_drawing_hands)\n",
    "        return img\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "790b3d25-cf0b-4d46-93d1-04e812b15457",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LandmarkExtractor:\n",
    "    def __init__(self):\n",
    "        self.mpHands = mp.solutions.hands # Load mediapipe hands module\n",
    "        self.mpFace = mp.solutions.face_mesh\n",
    "        self.hands = self.mpHands.Hands( # Initialize hands model\n",
    "            max_num_hands=2,\n",
    "            model_complexity=1,\n",
    "            min_detection_confidence=0.5,\n",
    "            min_tracking_confidence=0.5,\n",
    "            static_image_mode=False)\n",
    "        \n",
    "         # Load mediapipe face module\n",
    "        self.faces = self.mpFace.FaceMesh( # Initialize Face model\n",
    "            min_detection_confidence=0.5,\n",
    "            min_tracking_confidence=0.5,\n",
    "            static_image_mode=False)\n",
    "        \n",
    "    def findHands(self,img):\n",
    "        hands={}\n",
    "        imgRGB = cv2.cvtColor(img,cv2.COLOR_BGR2RGB) # Transform to RGB\n",
    "        results = self.hands.process(imgRGB) # Feeding image through Hands model\n",
    "        if results.multi_handedness!=None:\n",
    "            classification=[]\n",
    "            for hand in results.multi_handedness:\n",
    "                classification.append(MessageToDict(hand)['classification'][0])\n",
    "            print(classification)\n",
    "            if len(classification)==1:\n",
    "                hands[results.multi_hand_landmarks[0].classification[0].label]=results.multi_hand_landmarks[0]\n",
    "            else:\n",
    "                hands[results.multi_hand_landmarks[0].classification[0].label]=results.multi_hand_landmarks[0]\n",
    "                hands[results.multi_hand_landmarks[1].classification[0].label]=results.multi_hand_landmarks[1]\n",
    "\n",
    "            #for hand in classification:\n",
    "            #    index=hand['index']\n",
    "            #    if len(classification)==1 and index>0:\n",
    "            #        index=index-1\n",
    "            #    hands[hand['label']]=results.multi_hand_landmarks[index]\n",
    "        return hands # Returning values from model prediction\n",
    "        \n",
    "    def findFace(self, img):\n",
    "        imgRGB = cv2.cvtColor(img,cv2.COLOR_BGR2RGB) # Transform image to RGB\n",
    "        results = self.faces.process(imgRGB) # Feeding image through Face model\n",
    "        return results # Returning values from model prediction\n",
    "        \n",
    "    \n",
    "    def __getCoordinates(self,landmarks,index,scale,img_size): \n",
    "        x=landmarks.landmark[index].x\n",
    "        y=landmarks.landmark[index].y\n",
    "        z=landmarks.landmark[index].z\n",
    "        if scale:\n",
    "            x=x*img_size[0]\n",
    "            y=y*img_size[1]\n",
    "        return x,y,z  \n",
    "        \n",
    "    def getLipsLandmarks(self,resultsFace,scale=False,img_size=(700,720)):\n",
    "        list_lips_positions=[]\n",
    "        for cord in LIPS_POSITIONS:\n",
    "            landmarkovi=resultsFace.multi_face_landmarks[0]\n",
    "            x1,y1,z1=self.__getCoordinates(landmarkovi,cord[0],scale,img_size)\n",
    "            x2,y2,z2=self.__getCoordinates(landmarkovi,cord[1],scale,img_size)\n",
    "            \n",
    "            avg_x=float((x1+x2)/2)\n",
    "            avg_y=float((y1+y2)/2)\n",
    "            \n",
    "            list_lips_positions.append((avg_x,avg_y,z1))\n",
    "        return list_lips_positions\n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e77eb362-db4d-4ae9-97c9-3b94d2ad395a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoLoader:\n",
    "    def __init__(self):\n",
    "        self.fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        self.landmark_extractor=LandmarkExtractor()\n",
    "        self.drawing = Drawing()\n",
    "\n",
    "    def loadVideo(self,path,output_path=None):\n",
    "        \n",
    "        cap = cv2.VideoCapture(path)\n",
    "        if output_path is not None:\n",
    "            out = cv2.VideoWriter(output_path,self.fourcc, 15,(700,720))\n",
    "\n",
    "        use_frame=True\n",
    "        frames=[]  \n",
    "        i = 0\n",
    "        while(True):\n",
    "            ret, frame = cap.read() #reading frames\n",
    "            if ret: #if frame exist ret=True, otherwise False\n",
    "                if use_frame: # this means we will skip every other frame\n",
    "                    frame=frame[:, 300:1000,:] #cropping image, retainig all 3 rgb channels\n",
    "                    frames.append(frame)\n",
    "                    i+=1\n",
    "                    print((i*(1000/15))/1000)\n",
    "                    resultsFace=self.landmark_extractor.findFace(frame) #using function defined above to detect facial landmarks in a frame (findFace)\n",
    "                    resultsHands=self.landmark_extractor.findHands(frame) #using function defined above to detect hand landmarks in a frame (findHnds)\n",
    "                    if output_path is not None:\n",
    "                        out.write(self.drawing.drawLandmarks(frame.copy(),resultsFace,resultsHands)) #drawing landmarks on frames by using function defined above (drawLadmarks)\n",
    "        \n",
    "                    use_frame=False\n",
    "                else:\n",
    "                    use_frame=True\n",
    "            else:\n",
    "                break\n",
    "        if output_path is not None:\n",
    "            out.release() #close writing stream\n",
    "        return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00bb0008",
   "metadata": {},
   "outputs": [],
   "source": [
    "videoLoader = VideoLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6968f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06666666666666667\n",
      "0.13333333333333333\n",
      "0.2\n",
      "0.26666666666666666\n",
      "[{'index': 0, 'score': 0.993051, 'label': 'Left'}]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "classification",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8820\\2768654882.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvideoLoader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadVideo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../../ASLens - test data 1/-g45vqccdzI-1-rgb_front.mp4\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'new11.mp4'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8820\\61843037.py\u001b[0m in \u001b[0;36mloadVideo\u001b[1;34m(self, path, output_path)\u001b[0m\n\u001b[0;32m     23\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m                     \u001b[0mresultsFace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlandmark_extractor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindFace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#using function defined above to detect facial landmarks in a frame (findFace)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m                     \u001b[0mresultsHands\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlandmark_extractor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindHands\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#using function defined above to detect hand landmarks in a frame (findHnds)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0moutput_path\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m                         \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrawing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrawLandmarks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mresultsFace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mresultsHands\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#drawing landmarks on frames by using function defined above (drawLadmarks)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8820\\723460938.py\u001b[0m in \u001b[0;36mfindHands\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m                 \u001b[0mhands\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmulti_hand_landmarks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassification\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmulti_hand_landmarks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m                 \u001b[0mhands\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmulti_hand_landmarks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassification\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmulti_hand_landmarks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: classification"
     ]
    }
   ],
   "source": [
    "videoLoader.loadVideo(\"../../ASLens - test data 1/-g45vqccdzI-1-rgb_front.mp4\",output_path='new11.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a08893e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
