{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "6950eade-5f41-445b-8d25-dd05535f4daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import pandas as pd\n",
    "import mediapipe as mp\n",
    "from constants import LIPS_POSITIONS, FACE_OVAL,HAND_POSITIONS,HAND_CONNECTIONS\n",
    "from google.protobuf.json_format import MessageToDict\n",
    "from mediapipe.framework.formats import landmark_pb2\n",
    "from mediapipe.tasks.python.components.containers import NormalizedLandmark\n",
    "import h5py\n",
    "\n",
    "DEFAULT_LEFT_HAND = np.load(\"defaultLeftHand.npy\")\n",
    "DEFAULT_RIGHT_HAND = np.load(\"defaultRightHand.npy\")\n",
    "DEFAULT_FACE_OVAL = np.load(\"defaultFaceOval.npy\")\n",
    "DEFAULT_FACE_LIPS = np.load(\"defaultFaceLips.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7373f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Drawing:\n",
    "    def __init__(self):\n",
    "        self.mpFace = mp.solutions.face_mesh\n",
    "        self.mpDrawHands = mp.solutions.drawing_utils # Initializing drawing object for hands\n",
    "        self.mpDrawFace = mp.solutions.drawing_utils # Initializing drawing object for Face\n",
    "        self.mp_drawing_styles =mp.solutions.drawing_styles\n",
    "        self.mp_drawing_face = self.mpDrawFace.DrawingSpec(color=(0,0,200),thickness=0,circle_radius=1) #Initializing drawing specifications for face\n",
    "        self.mp_drawing_hands = self.mpDrawHands.DrawingSpec(color=(255,0,0),thickness=0,circle_radius=1) #Initializing drawing specifications for hand\n",
    "        self.mpHands = mp.solutions.hands\n",
    "    def drawLandmarks(self,img,faceLandmarks,handLandmarks,img_size=(700,720)):\n",
    "        img=img.copy()\n",
    "        colors={\"Right\":(100,100,100),\"Left\":(0,0,255)}\n",
    "        if faceLandmarks is not None:\n",
    "            for key in faceLandmarks:\n",
    "                for var in faceLandmarks[key]:\n",
    "                    cv2.circle(img, (int(var[0]*img_size[0]),int(var[1]*img_size[1])), 1, (0, 0, 255), -1)\n",
    "        for key in handLandmarks:\n",
    "            points={}\n",
    "            for i,var in enumerate(handLandmarks[key]):\n",
    "                point = (int(var[0]*img_size[0]),int(var[1]*img_size[1]))\n",
    "                cv2.circle(img, point, 3, colors[key], -1)\n",
    "                points[i]=point\n",
    "            for conn in HAND_CONNECTIONS:\n",
    "                cv2.line(img, points[conn], points[HAND_CONNECTIONS[conn]], (216, 223, 230), 2)\n",
    "        return img\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e699bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HandLandmarkExtractor:\n",
    "    def getHandLandmarks(self,hands,scale=False,img_size=(700,720)):\n",
    "        for key in hands:\n",
    "            list_hand_positions=[]\n",
    "           # print(type(resultsFace.multi_face_landmarks[0]))\n",
    "\n",
    "            for cord in HAND_POSITIONS:\n",
    "                x1,y1,z1=self.__getCoordinates(hands[key],cord,scale,img_size)\n",
    "\n",
    "                list_hand_positions.append((x1,y1,z1))\n",
    "            hands[key]= np.array(list_hand_positions)    \n",
    "        return hands    \n",
    "    def __getCoordinates(self,landmarks,index,scale,img_size): \n",
    "        x=landmarks.landmark[index].x\n",
    "        y=landmarks.landmark[index].y\n",
    "        z=landmarks.landmark[index].z\n",
    "        if scale:\n",
    "            x=x*img_size[0]\n",
    "            y=y*img_size[1]\n",
    "        return x,y,z  \n",
    "\n",
    "class FaceLandmarkExtractor:\n",
    "    def __getLipsLandmarks(self,resultsFace,scale=False,img_size=(700,720)):\n",
    "        list_lips_positions=[]\n",
    "        if resultsFace.multi_face_landmarks:\n",
    "            landmarkovi=resultsFace.multi_face_landmarks[0]\n",
    "\n",
    "            for cord in LIPS_POSITIONS:\n",
    "                x1,y1,z1=self.__getCoordinates(landmarkovi,cord[0],scale,img_size)\n",
    "                x2,y2,z2=self.__getCoordinates(landmarkovi,cord[1],scale,img_size)\n",
    "\n",
    "                avg_x=float((x1+x2)/2)\n",
    "                avg_y=float((y1+y2)/2)\n",
    "\n",
    "                list_lips_positions.append((avg_x,avg_y,z1))\n",
    "        return np.array(list_lips_positions)\n",
    " \n",
    "    def __getOvalFaceLandmarks(self,resultsFace,scale=False,img_size=(700,720)):\n",
    "        list_face_positions=[]\n",
    "       # print(type(resultsFace.multi_face_landmarks[0]))\n",
    "        if resultsFace.multi_face_landmarks:\n",
    "            landmarkovi=resultsFace.multi_face_landmarks[0]\n",
    "\n",
    "            for cord in FACE_OVAL:\n",
    "                x1,y1,z1=self.__getCoordinates(landmarkovi,cord,scale,img_size)\n",
    "\n",
    "                list_face_positions.append((x1,y1,z1))\n",
    "        return np.array(list_face_positions)\n",
    "    \n",
    "    def getFaceLandmarks(self,resultsFace,scale=False,img_size=(700,720)):\n",
    "        face_landmarks={}\n",
    "        face_landmarks[\"Lips\"]=self.__getLipsLandmarks(resultsFace,scale,img_size)\n",
    "        face_landmarks[\"Face\"]=self.__getOvalFaceLandmarks(resultsFace,scale,img_size)\n",
    "        return face_landmarks\n",
    "    \n",
    "    def __getCoordinates(self,landmarks,index,scale,img_size): \n",
    "        x=landmarks.landmark[index].x\n",
    "        y=landmarks.landmark[index].y\n",
    "        z=landmarks.landmark[index].z\n",
    "        if scale:\n",
    "            x=x*img_size[0]\n",
    "            y=y*img_size[1]\n",
    "        return x,y,z  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "790b3d25-cf0b-4d46-93d1-04e812b15457",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LandmarkExtractor:\n",
    "    def __init__(self):\n",
    "        self.mpHands = mp.solutions.hands # Load mediapipe hands module\n",
    "        self.mpFace = mp.solutions.face_mesh\n",
    "        self.hands = self.mpHands.Hands( # Initialize hands model\n",
    "            max_num_hands=2,\n",
    "            model_complexity=1,\n",
    "            min_detection_confidence=0.5,\n",
    "            min_tracking_confidence=0.5,\n",
    "            static_image_mode=False)\n",
    "        \n",
    "         # Load mediapipe face module\n",
    "        self.faces = self.mpFace.FaceMesh( # Initialize Face model\n",
    "            min_detection_confidence=0.5,\n",
    "            min_tracking_confidence=0.5,\n",
    "            static_image_mode=False)\n",
    "        self.handLandmarkExtractor=HandLandmarkExtractor()\n",
    "        self.faceLandmarkExtractor=FaceLandmarkExtractor()\n",
    "\n",
    "    def findHands(self,img):\n",
    "        hands={}\n",
    "        imgRGB = cv2.cvtColor(img,cv2.COLOR_BGR2RGB) # Transform to RGB\n",
    "        results = self.hands.process(imgRGB) # Feeding image through Hands model\n",
    "        if results.multi_handedness!=None:\n",
    "            for i,hand in enumerate(results.multi_handedness):\n",
    "                if hand.classification[0].label == \"Left\":\n",
    "                    handType=\"Right\"\n",
    "                else:\n",
    "                    handType=\"Left\"\n",
    "                hands[handType]=results.multi_hand_landmarks[i]\n",
    "\n",
    "\n",
    "        return hands # Returning values from model prediction\n",
    "    \n",
    "    def findFace(self, img):\n",
    "        imgRGB = cv2.cvtColor(img,cv2.COLOR_BGR2RGB) # Transform image to RGB\n",
    "        results = self.faces.process(imgRGB) # Feeding image through Face model\n",
    "        return results\n",
    "        \n",
    "    def getFaceLandmarks(self,resultsFace,scale=False,img_size=(700,720)):\n",
    "        return self.faceLandmarkExtractor.getFaceLandmarks(resultsFace,scale,img_size)\n",
    "    def getHandLandmarks(self,resultsHand,scale=False,img_size=(700,720)):\n",
    "        return self.handLandmarkExtractor.getHandLandmarks(resultsHand,scale,img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e77eb362-db4d-4ae9-97c9-3b94d2ad395a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoLoader:\n",
    "    def __init__(self):\n",
    "        self.fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        self.landmark_extractor=LandmarkExtractor()\n",
    "        self.drawing = Drawing()\n",
    "\n",
    "    def __processFrame(self,frame):\n",
    "        resultsFace=self.landmark_extractor.findFace(frame) #using function defined above to detect facial landmarks in a frame (findFace)\n",
    "        faceLandmarks=self.landmark_extractor.getFaceLandmarks(resultsFace)\n",
    "        \n",
    "        resultsHands=self.landmark_extractor.findHands(frame)\n",
    "        handLandmarks=self.landmark_extractor.getHandLandmarks(resultsHands)\n",
    "        \n",
    "        return faceLandmarks,handLandmarks\n",
    "    def exportFeaturesToVideo(self,frames,features,output_path):\n",
    "        outf = cv2.VideoWriter(output_path,self.fourcc, 15,(700,720))\n",
    "\n",
    "        faceLandmarks={}\n",
    "        handLandmarks={}\n",
    "\n",
    "        for i,frame in enumerate(frames):\n",
    "            faceLandmarks[\"Lips\"]=features['faceLips'][i]\n",
    "            faceLandmarks[\"Face\"]=features['faceOval'][i]\n",
    "            handLandmarks[\"Left\"]=features['handLeft'][i]\n",
    "            handLandmarks[\"Right\"]=features['handRight'][i]\n",
    "            outf.write(self.drawing.drawLandmarks(frame.copy(),faceLandmarks,handLandmarks))\n",
    "            #out.write(self.drawing.drawLandmarks(frames[i].copy(),faceLandmarks,handLandmarks)) #drawing landmarks on frames by using function defined above (drawLadmarks)\n",
    "        outf.release()\n",
    "\n",
    "    def loadVideo(self,path,output_path=None):\n",
    "        \n",
    "        cap = cv2.VideoCapture(path)\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        step = fps/15\n",
    "        if output_path is not None:\n",
    "            out = cv2.VideoWriter(output_path,self.fourcc, 15,(700,720))\n",
    "\n",
    "        frame_index = 0\n",
    "        next_frame_to_use = 0.0\n",
    "\n",
    "        frames=[]  \n",
    "        while(True):\n",
    "            ret, frame = cap.read() #reading frames\n",
    "            if not ret:\n",
    "                break\n",
    "            if ret: #if frame exist ret=True, otherwise False\n",
    "                if frame_index >= round(next_frame_to_use):\n",
    "                    frame=frame[:, 300:1000,:] #cropping image, retainig all 3 rgb channels\n",
    "                    frames.append(frame)\n",
    "                    \n",
    "                    if output_path is not None:\n",
    "                        faceLandmarks,handLandmarks = self.__processFrame(frame)\n",
    "                        out.write(self.drawing.drawLandmarks(frame.copy(),faceLandmarks,handLandmarks)) #drawing landmarks on frames by using function defined above (drawLadmarks)\n",
    "        \n",
    "                    next_frame_to_use += step\n",
    "            frame_index += 1\n",
    "        if output_path is not None:\n",
    "            out.release() #close writing stream\n",
    "        return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "ec534ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HandState:\n",
    "    def __init__(self, side, default):\n",
    "        self.side = side  # \"Left\" or \"Right\"\n",
    "        self.default = default\n",
    "        self.last = None\n",
    "        self.missing_count = 0\n",
    "\n",
    "    def update(self, handLandmarks, features):\n",
    "        key = f\"hand{self.side}\"\n",
    "        if self.side in handLandmarks:\n",
    "            current = handLandmarks[self.side]\n",
    "            features[key].append(current)\n",
    "\n",
    "            if 0 < self.missing_count <= 25 and self.last is not None:\n",
    "                for i in range(1, self.missing_count + 1):\n",
    "                    features[key][-(i + 1)] = self.last\n",
    "            self.missing_count = 0\n",
    "            self.last = current\n",
    "        else:\n",
    "            features[key].append( self.default)\n",
    "            self.missing_count += 1\n",
    "class FaceState:\n",
    "    def __init__(self, defaultLips,defaultOval):\n",
    "        self.defaultOval = defaultOval\n",
    "        self.defaultLips = defaultLips\n",
    "\n",
    "        self.lastLips = None\n",
    "        self.lastOval = None\n",
    "        self.missing_count = 0\n",
    "\n",
    "    def update(self, faceLandmarks, features):\n",
    "        if faceLandmarks[\"Face\"].size!=0 or faceLandmarks[\"Lips\"].size!=0:\n",
    "            features[\"faceLips\"].append(faceLandmarks[\"Lips\"])\n",
    "            features[\"faceOval\"].append(faceLandmarks[\"Face\"])\n",
    "\n",
    "            if 0 < self.missing_count <= 25 and self.lastOval is not None and self.lastLips is not None:\n",
    "                for i in range(1, self.missing_count + 1):\n",
    "                    features[\"faceLips\"][-(i + 1)] = self.lastLips\n",
    "                    features[\"faceOval\"][-(i + 1)] = self.lastOval\n",
    "\n",
    "            self.missing_count = 0\n",
    "            self.lastOval = faceLandmarks[\"Face\"]\n",
    "            self.lastLips = faceLandmarks[\"Lips\"]\n",
    "\n",
    "        else:\n",
    "            features[\"faceLips\"].append(self.defaultLips)\n",
    "            features[\"faceOval\"].append(self.defaultOval)\n",
    "            self.missing_count += 1\n",
    "class FeatureExtraction:\n",
    "    def __init__(self):\n",
    "        self.landmark_extractor=LandmarkExtractor()\n",
    "        self.video_loader=VideoLoader()\n",
    "        self.dataframe=[]\n",
    "    def __processFrame(self,frame):\n",
    "        resultsFace=self.landmark_extractor.findFace(frame) #using function defined above to detect facial landmarks in a frame (findFace)\n",
    "        faceLandmarks=self.landmark_extractor.getFaceLandmarks(resultsFace)\n",
    "        \n",
    "        resultsHands=self.landmark_extractor.findHands(frame)\n",
    "        handLandmarks=self.landmark_extractor.getHandLandmarks(resultsHands)\n",
    "        \n",
    "        return faceLandmarks,handLandmarks\n",
    "    \n",
    "    def extractFromVideo(self,path,output_path=None):\n",
    "        left_hand = HandState(\"Left\", DEFAULT_LEFT_HAND)\n",
    "        right_hand = HandState(\"Right\", DEFAULT_RIGHT_HAND)\n",
    "        face = FaceState(DEFAULT_FACE_LIPS,DEFAULT_FACE_OVAL)\n",
    "        frames = self.video_loader.loadVideo(path)\n",
    "        N = len(frames)\n",
    "        features={'handLeft':[],'handRight':[],\n",
    "                  'faceLips':[],'faceOval':[]}\n",
    "        for r,frame in enumerate(frames):\n",
    "            faceLandmarks,handLandmarks = self.__processFrame(frame)\n",
    "            face.update(faceLandmarks,features)\n",
    "            left_hand.update(handLandmarks, features)\n",
    "            right_hand.update(handLandmarks, features)                \n",
    "                    \n",
    "        if output_path is not None:\n",
    "            self.video_loader.exportFeaturesToVideo(frames,features,output_path)\n",
    "        features={'handLeft':np.array(features['handLeft']),'handRight':np.array(features['handRight']),\n",
    "                  'faceLips':np.array(features['faceLips']),'faceOval':np.array(features['faceOval'])}\n",
    "        return features\n",
    "    \n",
    "    def saveFeatures(self, path,features):\n",
    "        try:\n",
    "            file_name=path.split(\"\\\\\")[-1].split(\"-rgb_front\")[0][:-2]\n",
    "\n",
    "            with h5py.File(f\"landmarks/{file_name}.h5\", \"w\") as f:\n",
    "                f.create_dataset(\"handLeft\", data=features['handLeft'])\n",
    "                f.create_dataset(\"handRight\", data=features['handRight'])\n",
    "                f.create_dataset(\"faceOval\", data=features['faceOval'])\n",
    "                f.create_dataset(\"faceLips\", data=features['faceLips'])\n",
    "            self.dataframe.append({\"file_name\": file_name,\"landmarks\":f\"{file_name}.h5\"})\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(path)\n",
    "            features = self.extractFromVideo(path)\n",
    "            self.saveFeatures(path,features)\n",
    "    def getFeatures(self,folder_path):\n",
    "        for path in glob.glob(f'{folder_path}/*.mp4'):\n",
    "\n",
    "            features = self.extractFromVideo(path)\n",
    "            self.saveFeatures(path,features)\n",
    "        \n",
    "        df = pd.DataFrame(self.dataframe)\n",
    "        df.to_csv(\"AslLens-dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "00bb0008",
   "metadata": {},
   "outputs": [],
   "source": [
    "featureExtraction = FeatureExtraction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "710ee0c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.21.5'"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "1a08893e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "featureExtraction.getFeatures(\"../../ASLens - test data 1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
